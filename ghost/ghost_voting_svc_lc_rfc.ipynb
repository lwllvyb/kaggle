{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               id  bone_length  rotting_flesh  hair_length    has_soul\n",
      "count  371.000000   371.000000     371.000000   371.000000  371.000000\n",
      "mean   443.676550     0.434160       0.506848     0.529114    0.471392\n",
      "std    263.222489     0.132833       0.146358     0.169902    0.176129\n",
      "min      0.000000     0.061032       0.095687     0.134600    0.009402\n",
      "25%    205.500000     0.340006       0.414812     0.407428    0.348002\n",
      "50%    458.000000     0.434891       0.501552     0.538642    0.466372\n",
      "75%    678.500000     0.517223       0.603977     0.647244    0.600610\n",
      "max    897.000000     0.817001       0.932466     1.000000    0.935721\n",
      "------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 371 entries, 0 to 370\n",
      "Data columns (total 7 columns):\n",
      "id               371 non-null int64\n",
      "bone_length      371 non-null float64\n",
      "rotting_flesh    371 non-null float64\n",
      "hair_length      371 non-null float64\n",
      "has_soul         371 non-null float64\n",
      "color            371 non-null object\n",
      "type             371 non-null object\n",
      "dtypes: float64(4), int64(1), object(2)\n",
      "memory usage: 20.4+ KB\n",
      "None\n",
      "------\n",
      "   id  bone_length  rotting_flesh  hair_length  has_soul  color    type\n",
      "0   0     0.354512       0.350839     0.465761  0.781142  clear   Ghoul\n",
      "1   1     0.575560       0.425868     0.531401  0.439899  green  Goblin\n",
      "2   2     0.467875       0.354330     0.811616  0.791225  black   Ghoul\n",
      "3   4     0.776652       0.508723     0.636766  0.884464  black   Ghoul\n",
      "4   5     0.566117       0.875862     0.418594  0.636438  green   Ghost\n"
     ]
    }
   ],
   "source": [
    "# 导入训练集数据\n",
    "monster = pd.read_csv(\"..//input/train.csv\")\n",
    "\n",
    "# 输出统计信息\n",
    "print(monster.describe())\n",
    "print(\"------\")\n",
    "print(monster.info())\n",
    "print(\"------\")\n",
    "print(monster.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 类型转换为序列号\n",
    "color_label = LabelEncoder()\n",
    "monster['color'] = color_label.fit(monster['color']).transform(monster['color'])\n",
    "\n",
    "type_label = LabelEncoder()\n",
    "monster['type'] = type_label.fit(monster['type']).transform(monster['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature select\n",
    "def FeatureSelect(X, y, feature_name):\n",
    "    \n",
    "    \n",
    "    rf = RandomForestClassifier()\n",
    "    rf.fit(X, y)\n",
    "    return sorted(zip(map(lambda x: round(x, 4), rf.feature_importances_), feature_names), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1813, 'hair_soul'), (0.1639, 'bone_soul'), (0.1269, 'hair_bone'), (0.1199, 'hair_length'), (0.0914, 'rotting_flesh'), (0.089, 'has_soul'), (0.0883, 'bone_length'), (0.0629, 'rotting_soul'), (0.0611, 'rotting_hair'), (0.0153, 'color')]\n",
      "['hair_soul', 'bone_soul', 'hair_bone', 'hair_length', 'rotting_flesh', 'has_soul', 'bone_length', 'rotting_soul', 'rotting_hair']\n"
     ]
    }
   ],
   "source": [
    "def create_features(dataframe):\n",
    "    #Create some new variables.\n",
    "    dataframe['hair_soul'] = dataframe['hair_length'] * dataframe['has_soul']\n",
    "    dataframe['bone_soul'] = dataframe['bone_length'] * dataframe['has_soul']\n",
    "    dataframe['hair_bone'] = dataframe['hair_length'] * dataframe['bone_length']\n",
    "    dataframe['rotting_hair'] = dataframe['rotting_flesh'] * dataframe['hair_length']\n",
    "    dataframe['rotting_soul'] = dataframe['rotting_flesh'] * dataframe['has_soul']\n",
    "create_features(monster)\n",
    "\n",
    "feature_names = [\"bone_length\", \"rotting_flesh\", \"hair_length\", \"has_soul\", \"color\", \"hair_soul\",\"bone_soul\", \"hair_bone\", \"rotting_hair\", \"rotting_soul\",]\n",
    "\n",
    "X = monster[feature_names]\n",
    "y = monster['type']\n",
    "\n",
    "feature_importance = FeatureSelect(X, y, feature_names)\n",
    "print feature_importance\n",
    "feature_select = []\n",
    "for i in feature_importance:\n",
    "    if i[0] > 0.03:\n",
    "        feature_select.append(i[1])\n",
    "print feature_select\n",
    "X = monster[feature_select]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:0.760617760618\n",
      "Best param:{'multi_class': 'multinomial', 'C': 1, 'tol': 0.0001, 'solver': 'newton-cg'}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'solver' : ['newton-cg', 'lbfgs'],\n",
    "                  'multi_class' : ['ovr', 'multinomial'],\n",
    "                  'C' : [0.005, 0.01, 1, 10, 100, 1000],\n",
    "                  'tol': [0.0001, 0.001, 0.005]\n",
    "}\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "grid_search = GridSearchCV(log_reg, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best Score:%s\" % grid_search.best_score_)\n",
    "print(\"Best param:%s\" % grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7053571428571429"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg = LogisticRegression(multi_class=\"multinomial\", C=1, tol=0.0001, solver='newton-cg')\n",
    "log_reg.fit(X_train, y_train)\n",
    "log_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:0.772200772201\n",
      "Best param:{'max_leaf_nodes': 60, 'n_estimators': 10, 'min_samples_split': 5, 'min_weight_fraction_leaf': 0.1, 'criterion': 'gini', 'max_features': 'auto', 'max_depth': 20}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "                'n_estimators' : [100, 150],\n",
    "                'criterion' : ['gini'],\n",
    "                'max_features' : ['auto'],\n",
    "                'max_depth' : [5, 20, 100],\n",
    "                'min_samples_split' : [2, 5, 7],\n",
    "                'min_weight_fraction_leaf' : [0.0, 0.1],\n",
    "                'max_leaf_nodes' : [40, 60, 80],\n",
    "}\n",
    "\n",
    "rfc = RandomForestClassifier(criterion='entropy', n_jobs=-1)\n",
    "grid_search = GridSearchCV(rfc, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best Score:%s\" % grid_search.best_score_)\n",
    "print(\"Best param:%s\" % grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svc score:0.669642857143 \n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "predict_proba is not available when  probability=False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-cf79d65ae644>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mVclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mVclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sklearn/base.pyc\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    347\u001b[0m         \"\"\"\n\u001b[1;32m    348\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sklearn/ensemble/voting_classifier.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'estimators_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvoting\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'soft'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m             \u001b[0mmaj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# 'hard' voting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sklearn/ensemble/voting_classifier.pyc\u001b[0m in \u001b[0;36m_predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    208\u001b[0m                                  \" voting=%r\" % self.voting)\n\u001b[1;32m    209\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'estimators_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0mavg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_collect_probas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mavg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sklearn/ensemble/voting_classifier.pyc\u001b[0m in \u001b[0;36m_collect_probas\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_collect_probas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;34m\"\"\"Collect results from clf.predict calls. \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_predict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sklearn/svm/base.pyc\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m         \"\"\"\n\u001b[0;32m--> 615\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict_proba\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sklearn/svm/base.pyc\u001b[0m in \u001b[0;36m_check_proba\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobability\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m             raise AttributeError(\"predict_proba is not available when \"\n\u001b[0m\u001b[1;32m    583\u001b[0m                                  \" probability=False\")\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_impl\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'c_svc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'nu_svc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: predict_proba is not available when  probability=False"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "gnb = GaussianNB()\n",
    "\n",
    "svc = svm.SVC(kernel='linear')\n",
    "svc.fit(X_train, y_train)\n",
    "print (\"svc score:%s \" %svc.score(X_test, y_test))\n",
    "\n",
    "Vclf1 = VotingClassifier(estimators=[('LR', log_reg), \n",
    "                                     ('GNB', gnb), ('SVC', svc)], voting='hard')\n",
    "Vclf = VotingClassifier(estimators=[('LR', log_reg),\n",
    "                                     ('GNB', gnb), ('SVC', svc)], voting='soft', weights=[1,1,1])\n",
    "\n",
    "Vclf1.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
